{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Data Preprocessing\n",
    "1. **Loads MNIST dataset:**\n",
    "    - `(x_train, y_train), (x_test, y_test) = mnist.load_data()`\n",
    "2. **Prepares training data:**\n",
    "    - Reshapes first 60000 images: `images = x_train[0:60000].reshape(60000, 28*28) / 255`\n",
    "    - One-hot encodes labels: `labels = np.zeros((len(labels), 10)); ...`\n",
    "3. **Prepares test data:**\n",
    "    - Reshapes and normalizes all test images: `test_images_all = x_test.reshape(len(x_test), 28*28) / 255`\n",
    "    - One-hot encodes test labels: `test_labels_all = np.zeros((len(y_test), 10)); ...`\n",
    "    - Selects first 6000 test images and labels: `test_images, test_labels = test_images_all[0:6000], test_labels_all[0:6000]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# Preparing the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = (x_train[0:60000].reshape(60000,28*28) / 255, y_train[0:60000])\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images_all = x_test.reshape(len(x_test), 28*28) / 255\n",
    "test_labels_all = np.zeros((len(y_test), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels_all[i][l] = 1\n",
    "test_images = test_images_all[0:6000]\n",
    "test_labels = test_labels_all[0:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Training images: (60000, 784)\n",
      "The shape of Training labels: (60000, 10)\n",
      "The shape of test images: (6000, 784)\n",
      "The shape of test labels: (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of Training images: {images.shape}')\n",
    "print(f'The shape of Training labels: {labels.shape}')\n",
    "print(f'The shape of test images: {test_images.shape}')\n",
    "print(f'The shape of test labels: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization\n",
    "\n",
    "- **Layer Definitions:**\n",
    "    - `HIDDEN_LAYER_SIZE = 100`: Number of neurons in the hidden layer.\n",
    "    - `OUTPUT_LAYER_SIZE = 10`: Number of neurons in the output layer (matching 10 digits in MNIST).\n",
    "    - `INPUT_LAYER_SIZE = images.shape[1]`: Number of input features (784 pixels for MNIST images).\n",
    "- **Model Weights and Biases:**\n",
    "    - `W1`: Weights connecting input layer to hidden layer (784x100 matrix).\n",
    "    - `b1`: Biases for hidden layer neurons (1x100 vector).\n",
    "    - `W2`: Weights connecting hidden layer to output layer (100x10 matrix).\n",
    "    - `b2`: Biases for output layer neurons (1x10 vector).\n",
    "- **Random Initialization:**\n",
    "    - Weights are initialized with small random values between -1 and 1 for better learning.\n",
    "    - Biases are initialized to zero.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- Creates a basic neural network model with one hidden layer, ready for training on the prepared MNIST data.\n",
    "```**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_SIZE = 100\n",
    "OUTPUT_LAYER_SIZE = 10\n",
    "INPUT_LAYER_SIZE = images.shape[1]\n",
    "epsilon = 1e-8\n",
    "model = {\n",
    "    'W1': 2 * np.random.random((INPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE)) - 1, # 784 x HIDDEN_LAYER_SIZE\n",
    "    'b1': np.zeros((1, HIDDEN_LAYER_SIZE)), # 1 x HIDDEN_LAYER_SIZE\n",
    "    'W2': 2 * np.random.random((HIDDEN_LAYER_SIZE, OUTPUT_LAYER_SIZE)) - 1, # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE\n",
    "    'b2': np.zeros((1, OUTPUT_LAYER_SIZE)) # 1 x OUTPUT_LAYER_SIZE\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "**Defined Functions:**\n",
    "\n",
    "- **`sigmoid(x)`:**\n",
    "    - S-shaped curve that maps input values between 0 and 1.\n",
    "    - Commonly used in output layers for binary classification.\n",
    "    - `np.clip(x, -50, 50)` prevents numerical overflow.\n",
    "- **`sigmoid_derivative(x)`:**\n",
    "    - Calculates the derivative of the sigmoid function, used for backpropagation.\n",
    "- **`relu(x)`:**\n",
    "    - Rectified Linear Unit, outputs 0 for negative inputs and the input value itself for positive inputs.\n",
    "    - Promotes sparsity and helps prevent vanishing gradients.\n",
    "- **`relu2deriv(output)`:**\n",
    "    - Derivative of ReLU, used for backpropagation.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- These functions introduce non-linearity into neural networks, enabling them to learn complex patterns and decision boundaries.\n",
    "- They are essential for the training process, as they determine how neurons transform their inputs into outputs and how errors are propagated back to adjust weights and biases.\n",
    "```**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = np.clip(x, -50, 50)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "def relu2deriv(output):\n",
    "    return output > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **exponentially weighted averages (EWMAs) (The way how we looking at the last grdients):**\n",
    "\n",
    "**What they are:**\n",
    "\n",
    "- A way to calculate an average that gives more weight to recent data points, making it especially useful for tracking trends in time-series data.\n",
    "- It achieves this by assigning decreasing weights to older data points in an exponential manner—like an echo that gradually fades away.\n",
    "\n",
    "**How they work:**\n",
    "\n",
    "1. **Choose a weighting parameter (β):** This value, between 0 and 1, determines how quickly the weights decline. Higher β values place more emphasis on recent data.\n",
    "2. **Initialize the EWMA:** Start with the first data point as the initial EWMA value.\n",
    "3. **Calculate the EWMA for each subsequent data point:**\n",
    "   - Use the formula: `EWMA_t = β * EWMA_(t-1) + (1 - β) * x_t`\n",
    "      - `EWMA_t` is the EWMA at time t\n",
    "      - `EWMA_(t-1)` is the previous EWMA value\n",
    "      - `x_t` is the current data point\n",
    "4. **Update iteratively:** The EWMA value is updated with each new data point, creating a smooth, responsive average that reflects the most recent trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New input from the data is: 12 and the EMWA new value is 10\n",
      "New input from the data is: 15 and the EMWA new value is 10.2\n",
      "New input from the data is: 13 and the EMWA new value is 10.68\n",
      "New input from the data is: 18 and the EMWA new value is 10.911999999999999\n",
      "New input from the data is: 16 and the EMWA new value is 11.6208\n",
      "New input from the data is: 20 and the EMWA new value is 12.05872\n",
      "New input from the data is: 14 and the EMWA new value is 12.852848\n",
      "New input from the data is: 10 and the EMWA new value is 12.9675632\n",
      "New input from the data is: 16 and the EMWA new value is 12.67080688\n",
      "Exponentially Weighted Average: 13.003726192\n"
     ]
    }
   ],
   "source": [
    "# Data to be smoothed (e.g., a stock's price over time)\n",
    "data = np.array([10, 12, 15, 13, 18, 16, 20, 14, 10, 16])\n",
    "\n",
    "# Parameter controlling the weight given to recent data (between 0 and 1)\n",
    "beta = 0.9\n",
    "\n",
    "# Initialize the first value of the EWMA\n",
    "t_1 = data[0] # 10\n",
    "\n",
    "# Calculate the EWMA for each subsequent data point\n",
    "for value in data[1:]:\n",
    "    print(f'New input from the data is: {value} and the EMWA new value is {t_1}')\n",
    "    t_1 = beta * t_1 + (1 - beta) * value \n",
    "\n",
    "print(\"Exponentially Weighted Average:\", t_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Here's a theoretical and technical explanation of the Adam optimizer:**\n",
    "\n",
    "**Theoretical Overview:**\n",
    "\n",
    "- **Combines momentum and RMS Prop:** Adam incorporates the advantages of both approaches for efficient optimization.\n",
    "- **Momentum:** Accelerates learning in relevant directions, dampens oscillations, and helps escape local minima.\n",
    "- **RMS Prop:** Adjusts learning rates for each parameter based on historical gradients, leading to faster convergence and better generalization.\n",
    "- **Bias Correction:** Addresses initial bias in momentum and squared gradient estimates, allowing for faster progress in early stages and improving stability.\n",
    "\n",
    "\n",
    "   -  **Bias Correction:**\n",
    "      1. **Initial Bias:**\n",
    "      - Adam uses exponential moving averages to track momentum and squared gradients. These averages start close to zero and gradually build up over time.\n",
    "      - If not corrected, this initial bias towards zero can cause smaller updates in the early iterations, potentially slowing down convergence.\n",
    "\n",
    "      2. **Bias Correction:**\n",
    "      - To address this, Adam applies a bias correction factor to both the momentum and squared gradient estimates.\n",
    "      - The correction factor is 1 / (1 - beta^t), where beta is the decay rate (usually 0.9 or 0.999) and t is the current iteration.\n",
    "      - This factor effectively scales up the estimates, compensating for the initial bias towards zero and allowing for more meaningful updates even in the early stages <span style=\"color: orange;\">(Explained with code in Draft cells sector)</span>.\n",
    "\n",
    "      3. **Impact on Updates:**\n",
    "      - The corrected momentum and squared gradient estimates are then used to update the weights:\n",
    "         - Weight update = learning_rate * corrected_momentum / sqrt(corrected_squared_gradient + epsilon)\n",
    "      - This ensures that updates are appropriately scaled even when the averages are small, leading to faster convergence and smoother training.\n",
    "\n",
    "      4. **Key Points:**\n",
    "      - Bias correction doesn't directly force weights to be larger. It adjusts the momentum and squared gradient estimates to address their initial bias, allowing for more effective updates.\n",
    "      - It's crucial for faster convergence and smoother training, especially in the early stages.\n",
    "      - It's a key component of the Adam optimizer, contributing to its overall efficiency and effectiveness.\n",
    "\n",
    "\n",
    "**Technical Implementation:**\n",
    "\n",
    "1. **Initialization:**\n",
    "   - Set momentum terms (mt) and squared gradients (vt) to zero for all parameters.\n",
    "   - Choose hyperparameters: beta1 (momentum decay), beta2 (squared gradient decay), learning rate (α), and epsilon (small constant for numerical stability).\n",
    "\n",
    "2. **Iteration:**\n",
    "   - For each parameter θ at iteration t:\n",
    "     - Calculate gradient (gt).\n",
    "     - Update momentum: mt = beta1 * mt-1 + (1 - beta1) * gt.\n",
    "     - Update squared gradient: vt = beta2 * vt-1 + (1 - beta2) * gt^2.\n",
    "     - Bias correction: mt_hat = mt / (1 - beta1^t), vt_hat = vt / (1 - beta2^t).\n",
    "     - Update parameter: θt = θt-1 - α * mt_hat / (sqrt(vt_hat) + ε).\n",
    "\n",
    "3. **Repeat:**\n",
    "   - Continue iterations until convergence or specified number of epochs.\n",
    "\n",
    "**Key Hyperparameters:**\n",
    "\n",
    "- **beta1:** Controls momentum (common values: 0.9, 0.99).\n",
    "- **beta2:** Controls adaptive learning rates (common values: 0.999).\n",
    "- **learning rate (α):** Initial step size (tuning needed).\n",
    "- **epsilon (ε):** Small constant for numerical stability (common value: 1e-8).\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Faster convergence compared to standard gradient descent.\n",
    "- Often converges to a better solution.\n",
    "- Works well with sparse gradients and noisy data.\n",
    "- Generally robust to hyperparameter choices.\n",
    "- Common choice for deep learning and large-scale optimization problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Explaination of the `train_mnist` function:**\n",
    "\n",
    "**1. Function Purpose:**\n",
    "- Trains a neural network model on the MNIST dataset using mini-batch gradient descent.\n",
    "\n",
    "**2. Parameters:**\n",
    "- `images`: Input images (array of shape `(num_samples, 784)`).\n",
    "- `labels`: True labels (array of shape `(num_samples, OUTPUT_LAYER_SIZE)`).\n",
    "- `model`: Dictionary containing model weights and biases.\n",
    "- `lr`: Learning rate (default: 0.01).\n",
    "- `Beta1`: Controls momentum (common values: 0.9, 0.99) (default: 0.9).\n",
    "- `Beta2`: Controls adaptive learning rates (common values: 0.999). (default: 0.999).\n",
    "- `decay_rate`: Learning rate decay rate (default: 0.95).\n",
    "- `mini_batch_size`: Size of mini-batches (default: 128).\n",
    "\n",
    "**3. Steps:**\n",
    "\n",
    "1. **Mini-Batch Loop:**\n",
    "   - Iterates through the dataset in mini-batches.\n",
    "2. **Extract Mini-Batch:**\n",
    "   - Gets a subset of images and labels for the current mini-batch.\n",
    "3. **Forward Pass:**\n",
    "   - Calculates outputs for the mini-batch using the model.\n",
    "   - Applies ReLU in the hidden layer and sigmoid in the output layer.\n",
    "4. **Calculate Error:**\n",
    "   - Computes the difference between predicted outputs and true labels.\n",
    "5. **Backpropagation:**\n",
    "   - Calculates error gradients for the output and hidden layers.\n",
    "   - Uses derivatives of ReLU and sigmoid functions.\n",
    "6. **Weights Update:**\n",
    "   - Calculating the momentum and squared gradient of each weight and biases.\n",
    "   - Correcting the Bias in the momentum and squared gradient.\n",
    "   - Adjusts model weights and biases.\n",
    "7. **Learning Rate Decay:**\n",
    "   - Decreases the learning rate after each mini-batch to aid convergence.\n",
    "8. **Return Updated Model:**\n",
    "   - Returns the model with updated weights and biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(images, labels, model, lr=0.01, beta1=0.9,beta2=0.999, decay_rate=0.95, mini_batch_size=128):\n",
    "    num_samples = len(images)\n",
    "    vW1 = np.zeros_like(model['W1']) # Velocity of W1\n",
    "    vb1 = np.zeros_like(model['b1']) # Velocity of b1\n",
    "    vW2 = np.zeros_like(model['W2']) # Velocity of W2\n",
    "    vb2 = np.zeros_like(model['b2']) # Velocity of b2\n",
    "    sdw2 = 0\n",
    "    sdw1 = 0\n",
    "    sdb1 = 0\n",
    "    sdb2 = 0\n",
    "        \n",
    "    for i in range(0, num_samples, mini_batch_size):\n",
    "        # Extract mini-batch\n",
    "        batch_images = images[i:i+mini_batch_size] \n",
    "        batch_labels = labels[i:i+mini_batch_size] \n",
    "        \n",
    "        # Forward pass\n",
    "        hidden_layer = relu(batch_images.dot(model['W1']) + model['b1']) # BATCHSIZE x 784 * 784 x HIDDEN_LAYER_SIZE = BATCHSIZE x HIDDEN_LAYER_SIZE\n",
    "        output_layer = sigmoid(hidden_layer.dot(model['W2']) + model['b2']) # BATCHSIZE x HIDDEN_LAYER_SIZE * HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE = BATCHSIZE x OUTPUT_LAYER_SIZE\n",
    "\n",
    "        # Calculate the error/loss\n",
    "        error = output_layer - batch_labels # BATCHSIZE x OUTPUT_LAYER_SIZE # calculates the pure error, or loss, which is used for computing derivatives in backpropagation\n",
    "        loss = np.mean((output_layer - batch_labels) ** 2)\n",
    "\n",
    "        # Backpropagation\n",
    "        output_layer_delta = error * sigmoid_derivative(output_layer) # BATCHSIZE x OUTPUT_LAYER_SIZE\n",
    "        hidden_layer_delta = output_layer_delta.dot(model['W2'].T) * relu2deriv(hidden_layer) # BATCHSIZE x OUTPUT_LAYER_SIZE * OUTPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE = BATCHSIZE x HIDDEN_LAYER_SIZE\n",
    "\n",
    "        # Weights Update\n",
    "        vW2 = beta1 * vW2 + (1 - beta1) * hidden_layer.T.dot(output_layer_delta)\n",
    "        sdw2 = beta2 * sdw2 + (1 - beta2) * (hidden_layer.T.dot(output_layer_delta) ** 2) # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE\n",
    "\n",
    "        vW1 = beta1 * vW1 + (1 - beta1) * batch_images.T.dot(hidden_layer_delta)\n",
    "        sdw1 = beta2 * sdw1 + (1 - beta2) * (batch_images.T.dot(hidden_layer_delta) ** 2) # INPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE\n",
    "        \n",
    "        vb2 = beta1 * vb2 + (1 - beta1) * np.mean(output_layer_delta)\n",
    "        sdb2 = beta2 * sdb2 + (1 - beta2) * np.mean(output_layer_delta ** 2) # meaning the output_layer_delta to convert its shape from BTACHSIZE x OUTPUT_LAYER_SIZE to b size\n",
    "\n",
    "        vb1 = beta1 * vb1 + (1 - beta1) * np.mean(hidden_layer_delta)\n",
    "        sdb1 = beta2 * sdb1 + (1 - beta2) * np.mean(hidden_layer_delta ** 2) # meaning the hidden_layer_delta to convert its shape from BTACHSIZE x HIDDEN_LAYER_SIZE to b size\n",
    "\n",
    "        # Bias Correction\n",
    "        vW2_corrected = vW2 / (1 - beta1)\n",
    "        sdw2_corrected = sdw2 / (1 - beta2)\n",
    "        vW1_corrected = vW1 / (1 - beta1)\n",
    "        sdw1_corrected = sdw1 / (1 - beta2)\n",
    "        vb2_corrected = vb2 / (1 - beta1)\n",
    "        sdb2_corrected = sdb2 / (1 - beta2)\n",
    "        vb1_corrected = vb1 / (1 - beta1)\n",
    "        sdb1_corrected = sdb1 / (1 - beta2)\n",
    "\n",
    "        model['W2'] -= lr * (vW2_corrected/np.sqrt(sdw2_corrected + epsilon)) # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE\n",
    "        model['W1'] -= lr * (vW1_corrected/np.sqrt(sdw1_corrected + epsilon)) # INPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE\n",
    "        model['b1'] -= lr * (vb1_corrected / np.sqrt(sdb1_corrected + epsilon)) # 1 x OUTPUT_LAYER_SIZE\n",
    "        model['b2'] -= lr * (vb2_corrected / np.sqrt(sdb2_corrected + epsilon)) # 1 x HIDDEN_LAYER_SIZE\n",
    "\n",
    "    # Learning rate decay\n",
    "    lr *= decay_rate\n",
    "\n",
    "    return model, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Implementation of the prediction and evaluation function**\n",
    "\n",
    "**1. `model_prediction(model, X)`:**\n",
    "\n",
    "- **Purpose:** Generates predictions for given inputs using the model.\n",
    "- **Steps:**\n",
    "    1. **Calculate hidden layer outputs:** Applies ReLU activation to the weighted sum of inputs and hidden layer weights (`model['W1']`) plus biases (`model['b1']`).\n",
    "    2. **Calculate output layer outputs:** Applies sigmoid activation to the weighted sum of hidden layer outputs and output layer weights (`model['W2']`) plus biases (`model['b2']`).\n",
    "    3. **Return output layer:** Returns raw output scores from the output layer, representing predicted probabilities (or confidence scores) for each class.\n",
    "\n",
    "**2. `evaluate_accuracy(model, X, y_true)`:**\n",
    "\n",
    "- **Purpose:** Calculates overall accuracy of the model's predictions on a dataset.\n",
    "- **Steps:**\n",
    "    1. **Generate model predictions:** Calls `model_prediction` to get predictions for all inputs in `X`.\n",
    "    2. **Extract predicted labels:** Finds the index of the highest-scoring class for each prediction using `np.argmax`.\n",
    "    3. **Extract true labels:** Extracts true class labels from `y_true` (assuming one-hot encoded).\n",
    "    4. **Compare predictions and true labels:** Calculates the proportion of correct predictions.\n",
    "    5. **Return accuracy:** Returns the overall accuracy as a percentage.\n",
    "\n",
    "**3. `evaluate_accuracy_one_sample(model, X, y_true)`:**\n",
    "\n",
    "- **Purpose:** Evaluates accuracy for a single sample (input and true label).\n",
    "- **Steps:**\n",
    "    1. **Generate model prediction:** Calls `model_prediction` for the single input `X`.\n",
    "    2. **Extract predicted label:** Finds the index of the highest-scoring class in the prediction.\n",
    "    3. **Extract true label:** Extracts the true class label from `y_true`.\n",
    "    4. **Compare prediction and true label:** Checks if they match.\n",
    "    5. **Return accuracy:** Returns `True` if prediction is correct, `False` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, X):\n",
    "    hidden_layer = relu(X.dot(model['W1']) + model['b1']) \n",
    "    output_layer = sigmoid(hidden_layer.dot(model['W2']) + model['b2']) \n",
    "    return output_layer\n",
    "\n",
    "def evaluate_accuracy(model, X, y_true):\n",
    "    predictions = model_prediction(model, X)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    return accuracy\n",
    "def evaluate_accuracy_one_sample(model, X, y_true):\n",
    "    predictions = model_prediction(model, X)\n",
    "    predicted_labels = np.argmax(predictions)\n",
    "    true_labels = np.argmax(y_true)\n",
    "    \n",
    "    accuracy = predicted_labels == true_labels\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Training Setup:**\n",
    "\n",
    "- **Lists for Accuracies:** `train_accuracies` and `val_accuracies` store accuracies from each epoch for tracking progress.\n",
    "- **Early Stopping:**\n",
    "    - `no_improvement_count` tracks epochs without validation improvement.\n",
    "    - `patience` sets the maximum number of epochs without improvement before stopping (50 in this case).\n",
    "    - `best_val_acc` stores the best validation accuracy achieved so far.\n",
    "\n",
    "**2. Training Loop:**\n",
    "\n",
    "- **Iterates up to 500 epochs:** Runs a maximum of 500 training iterations.\n",
    "- **Model Training:**\n",
    "    - Calls the `train_mnist` function to train the model on the training data (`images`, `labels`).\n",
    "        - Uses hyperparameters: learning rate (`lr`), regularization type (`regularization`), regularization strength (`reg_lambda`), and mini-batch size (`mini_batch_size`).\n",
    "- **Accuracy Calculation:**\n",
    "    - Evaluates accuracy on both training and validation sets using `evaluate_accuracy`.\n",
    "- **Storing Accuracies:** Appends accuracies to their respective lists for plotting.\n",
    "- **Printing Progress:** Prints epoch number and accuracies.\n",
    "- **Best Model Tracking:**\n",
    "    - If validation accuracy improves, updates `best_val_acc`, copies model weights to `best_model`, and resets `no_improvement_count`.\n",
    "- **Early Stopping:**\n",
    "    - If validation accuracy hasn't improved for `patience` epochs, stops training and prints a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.6471, Val Accuracy: 0.6285, Current Loss: 0.0927\n",
      "Epoch 2, Train Accuracy: 0.8411, Val Accuracy: 0.8122, Current Loss: 0.0390\n",
      "Epoch 3, Train Accuracy: 0.8877, Val Accuracy: 0.8635, Current Loss: 0.0259\n",
      "Epoch 4, Train Accuracy: 0.9119, Val Accuracy: 0.8875, Current Loss: 0.0185\n",
      "Epoch 5, Train Accuracy: 0.9266, Val Accuracy: 0.9053, Current Loss: 0.0151\n",
      "Epoch 6, Train Accuracy: 0.9359, Val Accuracy: 0.9158, Current Loss: 0.0131\n",
      "Epoch 7, Train Accuracy: 0.9438, Val Accuracy: 0.9225, Current Loss: 0.0121\n",
      "Epoch 8, Train Accuracy: 0.9498, Val Accuracy: 0.9268, Current Loss: 0.0115\n",
      "Epoch 9, Train Accuracy: 0.9546, Val Accuracy: 0.9285, Current Loss: 0.0107\n",
      "Epoch 10, Train Accuracy: 0.9587, Val Accuracy: 0.9328, Current Loss: 0.0101\n",
      "Epoch 11, Train Accuracy: 0.9622, Val Accuracy: 0.9352, Current Loss: 0.0096\n",
      "Epoch 12, Train Accuracy: 0.9652, Val Accuracy: 0.9382, Current Loss: 0.0089\n",
      "Epoch 13, Train Accuracy: 0.9678, Val Accuracy: 0.9400, Current Loss: 0.0082\n",
      "Epoch 14, Train Accuracy: 0.9697, Val Accuracy: 0.9422, Current Loss: 0.0077\n",
      "Epoch 15, Train Accuracy: 0.9715, Val Accuracy: 0.9447, Current Loss: 0.0071\n",
      "Epoch 16, Train Accuracy: 0.9734, Val Accuracy: 0.9458, Current Loss: 0.0069\n",
      "Epoch 17, Train Accuracy: 0.9752, Val Accuracy: 0.9472, Current Loss: 0.0067\n",
      "Epoch 18, Train Accuracy: 0.9767, Val Accuracy: 0.9487, Current Loss: 0.0065\n",
      "Epoch 19, Train Accuracy: 0.9783, Val Accuracy: 0.9493, Current Loss: 0.0063\n",
      "Epoch 20, Train Accuracy: 0.9798, Val Accuracy: 0.9503, Current Loss: 0.0062\n",
      "Epoch 21, Train Accuracy: 0.9810, Val Accuracy: 0.9517, Current Loss: 0.0062\n",
      "Epoch 22, Train Accuracy: 0.9823, Val Accuracy: 0.9528, Current Loss: 0.0061\n",
      "Epoch 23, Train Accuracy: 0.9832, Val Accuracy: 0.9535, Current Loss: 0.0061\n",
      "Epoch 24, Train Accuracy: 0.9840, Val Accuracy: 0.9537, Current Loss: 0.0060\n",
      "Epoch 25, Train Accuracy: 0.9849, Val Accuracy: 0.9547, Current Loss: 0.0060\n",
      "Epoch 26, Train Accuracy: 0.9858, Val Accuracy: 0.9555, Current Loss: 0.0059\n",
      "Epoch 27, Train Accuracy: 0.9866, Val Accuracy: 0.9560, Current Loss: 0.0059\n",
      "Epoch 28, Train Accuracy: 0.9871, Val Accuracy: 0.9565, Current Loss: 0.0059\n",
      "Epoch 29, Train Accuracy: 0.9879, Val Accuracy: 0.9570, Current Loss: 0.0060\n",
      "Epoch 30, Train Accuracy: 0.9886, Val Accuracy: 0.9577, Current Loss: 0.0059\n",
      "Epoch 31, Train Accuracy: 0.9892, Val Accuracy: 0.9582, Current Loss: 0.0059\n",
      "Epoch 32, Train Accuracy: 0.9898, Val Accuracy: 0.9585, Current Loss: 0.0058\n",
      "Epoch 33, Train Accuracy: 0.9903, Val Accuracy: 0.9585, Current Loss: 0.0057\n",
      "Epoch 34, Train Accuracy: 0.9907, Val Accuracy: 0.9593, Current Loss: 0.0055\n",
      "Epoch 35, Train Accuracy: 0.9911, Val Accuracy: 0.9602, Current Loss: 0.0055\n",
      "Epoch 36, Train Accuracy: 0.9917, Val Accuracy: 0.9598, Current Loss: 0.0054\n",
      "Epoch 37, Train Accuracy: 0.9920, Val Accuracy: 0.9605, Current Loss: 0.0054\n",
      "Epoch 38, Train Accuracy: 0.9923, Val Accuracy: 0.9608, Current Loss: 0.0053\n",
      "Epoch 39, Train Accuracy: 0.9928, Val Accuracy: 0.9612, Current Loss: 0.0053\n",
      "Epoch 40, Train Accuracy: 0.9931, Val Accuracy: 0.9617, Current Loss: 0.0052\n",
      "Epoch 41, Train Accuracy: 0.9935, Val Accuracy: 0.9613, Current Loss: 0.0051\n",
      "Epoch 42, Train Accuracy: 0.9938, Val Accuracy: 0.9610, Current Loss: 0.0052\n",
      "Epoch 43, Train Accuracy: 0.9941, Val Accuracy: 0.9613, Current Loss: 0.0050\n",
      "Epoch 44, Train Accuracy: 0.9944, Val Accuracy: 0.9613, Current Loss: 0.0049\n",
      "Epoch 45, Train Accuracy: 0.9946, Val Accuracy: 0.9612, Current Loss: 0.0049\n",
      "Epoch 46, Train Accuracy: 0.9950, Val Accuracy: 0.9607, Current Loss: 0.0049\n",
      "Epoch 47, Train Accuracy: 0.9952, Val Accuracy: 0.9615, Current Loss: 0.0046\n",
      "Epoch 48, Train Accuracy: 0.9954, Val Accuracy: 0.9615, Current Loss: 0.0044\n",
      "Epoch 49, Train Accuracy: 0.9955, Val Accuracy: 0.9610, Current Loss: 0.0044\n",
      "Epoch 50, Train Accuracy: 0.9958, Val Accuracy: 0.9612, Current Loss: 0.0042\n",
      "Early stopping: Validation accuracy did not improve for 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "no_improvement_count = 0\n",
    "patience = 10\n",
    "best_val_acc = 0.0\n",
    "for iteration in range(500):\n",
    "    # Training the model\n",
    "    model, loss = train_mnist(images, labels, model, lr=0.001, beta1=0.9,beta2 = 0.999, mini_batch_size=512)\n",
    "\n",
    "    # Calculating the accuracies\n",
    "    train_accuracy = evaluate_accuracy(model, images, labels)\n",
    "    val_accuracy = evaluate_accuracy(model, test_images, test_labels)\n",
    "\n",
    "    # Storing the accuracies to plot it\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {iteration + 1}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Current Loss: {loss:.4f}\")\n",
    "    # Picking up the best model weights and accuracy\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        best_model = model.copy()\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    if no_improvement_count >= patience:\n",
    "        print(\"Early stopping: Validation accuracy did not improve for 10 epochs.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the accuracies\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy on Validation set is: 96.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model Accuracy on Validation set is: {np.round(best_val_acc * 100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Testing on Remaining Test Set:**\n",
    "- It loops through images not used for validation.\n",
    "- For each image:\n",
    "    - Gets a prediction from the best model.\n",
    "    - Extracts predicted and true labels.\n",
    "    - Stores them as pairs for later analysis.\n",
    "\n",
    "**2. Calculating Accuracy:**\n",
    "- Counts correct predictions using list comprehension.\n",
    "- Divides correct by total to get accuracy.\n",
    "\n",
    "**3. Printing Results:**\n",
    "- Outputs number of correct predictions, total predictions, and accuracy percentage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions count is: 3918 out of 4000\n",
      "The accuracy is: 97.95%\n"
     ]
    }
   ],
   "source": [
    "# Iterating over the rest of the test images that we didnt include in val_set\n",
    "all_preds = []\n",
    "for image in range(len(test_labels), len(test_labels_all)):\n",
    "    test_image = test_images_all[image]\n",
    "    test_label = test_labels_all[image]\n",
    "    predicted_label = model_prediction(best_model, test_image)\n",
    "    predicted_label = np.argmax(predicted_label)\n",
    "    test_label = np.argmax(test_label)\n",
    "    all_preds.append((predicted_label,test_label))\n",
    "\n",
    "correct_predictions = sum(1 for pred, true_label in all_preds if pred == true_label)\n",
    "accuracy = np.round(correct_predictions / len(all_preds) * 100, 2)\n",
    "\n",
    "print(f'Correct predictions count is: {correct_predictions} out of {len(all_preds)}\\nThe accuracy is: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting a random images\n",
    "res = evaluate_accuracy_one_sample(best_model, test_images_all[6123], test_labels_all[6123])\n",
    "res \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oringinal x:\n",
      "[[-0.75275929  2.70428584  1.39196365]\n",
      " [ 0.59195091 -2.06388816 -2.06403288]\n",
      " [-2.65149833  2.19705687  0.60669007]]\n",
      "\n",
      "corrected x:\n",
      "[[ -7.52759287  27.04285838  13.91963651]\n",
      " [  5.91950905 -20.63888157 -20.64032878]\n",
      " [-26.51498327  21.97056875   6.0669007 ]]\n",
      "\n",
      "divide without correction x:\n",
      "[[-0.15055186  0.54085717  0.27839273]\n",
      " [ 0.11839018 -0.41277763 -0.41280658]\n",
      " [-0.53029967  0.43941137  0.12133801]]\n",
      "\n",
      "divide with correction x:\n",
      "[[-1.50551857  5.40857168  2.7839273 ]\n",
      " [ 1.18390181 -4.12777631 -4.12806576]\n",
      " [-5.30299665  4.39411375  1.21338014]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.uniform(-3,3, size=(3,3))\n",
    "x_corr = x/(1 - 0.9)\n",
    "print(f'oringinal x:\\n{x}')\n",
    "print()\n",
    "print(f'corrected x:\\n{x_corr}')\n",
    "print()\n",
    "print(f'divide without correction x:\\n{x/np.sqrt(25)}')\n",
    "print()\n",
    "print(f'divide with correction x:\\n{x_corr/np.sqrt(25)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label of example 1:\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "Prediction of the model of example 1:\n",
      " [6.47372058e-16 1.51516119e-14 1.21312300e-08 5.80540473e-04\n",
      " 4.35876152e-19 8.43702830e-15 1.18511954e-14 9.99999674e-01\n",
      " 1.07495463e-10 8.98992872e-10]\n",
      "\n",
      "Subtraction of the predection and the actual label example 1:\n",
      " [ 6.47372058e-16  1.51516119e-14  1.21312300e-08  5.80540473e-04\n",
      "  4.35876152e-19  8.43702830e-15  1.18511954e-14 -3.26392648e-07\n",
      "  1.07495463e-10  8.98992872e-10]\n",
      "-------------------------\n",
      "(16, 10)\n",
      "(16, 10)\n"
     ]
    }
   ],
   "source": [
    "# Simulating the error \n",
    "np.random.seed(42)\n",
    "preds = model_prediction(model, test_images[0:16]) # 16x10\n",
    "print(f'Actual Label of example 1:\\n {test_labels[0:16][0]}')\n",
    "print()\n",
    "print(f'Prediction of the model of example 1:\\n {preds[0]}')\n",
    "print()\n",
    "print(f'Subtraction of the predection and the actual label example 1:\\n {(preds - test_labels[0:16])[0]}') # This is the pure error which is we are going to calculate the dervitive according to it\n",
    "print('-------------------------')\n",
    "print((test_labels[0:16]).shape)\n",
    "print((preds.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\n",
      "1.0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(preds, axis=1))\n",
    "print(np.argmax(test_labels[0:16], axis=1))\n",
    "print(np.mean(np.argmax(preds, axis=1) == np.argmax(test_labels[0:16], axis=1)))\n",
    "print(np.argmax(preds[0])) # taking a list and returning the index of the greatest number of this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((HIDDEN_LAYER_SIZE, 1))\n",
    "test2 = test.reshape(1, -1)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15909362  0.33998078  0.01211581  0.24532239]]\n",
      "\n",
      "[[-0.12545988  0.45071431  0.23199394  0.09865848]\n",
      " [-0.34398136 -0.34400548 -0.44191639  0.36617615]\n",
      " [ 0.10111501  0.20807258 -0.47941551  0.46990985]]\n",
      "\n",
      "[[-0.12386894  0.4473145   0.23187278  0.09620526]\n",
      " [-0.34239042 -0.34740529 -0.44203755  0.36372292]\n",
      " [ 0.10270595  0.20467277 -0.47953666  0.46745663]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "weight = np.random.uniform(-0.5,0.5, size=(3,4))\n",
    "out_delta = np.random.uniform(0,1, size=(1,3))\n",
    "hidden_delta = out_delta.dot(weight)\n",
    "\n",
    "print(hidden_delta)\n",
    "print()\n",
    "print(weight)\n",
    "weight -= 0.01 * hidden_delta\n",
    "print()\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00025092  0.00090143  0.00046399  0.00019732]\n",
      " [-0.00068796 -0.00068801 -0.00088383  0.00073235]\n",
      " [ 0.00020223  0.00041615 -0.00095883  0.00093982]\n",
      " [ 0.00066489 -0.00057532 -0.00063635 -0.00063319]]\n",
      "\n",
      "[[-0.00025091  0.00090144  0.000464    0.00019733]\n",
      " [-0.00068795 -0.000688   -0.00088382  0.00073236]\n",
      " [ 0.00020224  0.00041616 -0.00095882  0.00093983]\n",
      " [ 0.0006649  -0.00057531 -0.00063634 -0.00063318]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sdw = np.random.uniform(-0.001,0.001, size=(4,4))\n",
    "print(sdw)\n",
    "print()\n",
    "print(sdw + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0,5,size=(128,10))\n",
    "b = np.random.randint(2,3, size=(1,10))\n",
    "print((b - x).shape)\n",
    "print((b - np.mean(x)).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
