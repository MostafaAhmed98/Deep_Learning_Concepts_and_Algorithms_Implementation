{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Data Preprocessing\n",
    "1. **Loads MNIST dataset:**\n",
    "    - `(x_train, y_train), (x_test, y_test) = mnist.load_data()`\n",
    "2. **Prepares training data:**\n",
    "    - Reshapes first 60000 images: `images = x_train[0:60000].reshape(60000, 28*28) / 255`\n",
    "    - One-hot encodes labels: `labels = np.zeros((len(labels), 10)); ...`\n",
    "3. **Prepares test data:**\n",
    "    - Reshapes and normalizes all test images: `test_images_all = x_test.reshape(len(x_test), 28*28) / 255`\n",
    "    - One-hot encodes test labels: `test_labels_all = np.zeros((len(y_test), 10)); ...`\n",
    "    - Selects first 6000 test images and labels: `test_images, test_labels = test_images_all[0:6000], test_labels_all[0:6000]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# Preparing the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = (x_train[0:60000].reshape(60000,28*28) / 255, y_train[0:60000])\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images_all = x_test.reshape(len(x_test), 28*28) / 255\n",
    "test_labels_all = np.zeros((len(y_test), 10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels_all[i][l] = 1\n",
    "test_images = test_images_all[0:6000]\n",
    "test_labels = test_labels_all[0:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Training images: (60000, 784)\n",
      "The shape of Training labels: (60000, 10)\n",
      "The shape of test images: (6000, 784)\n",
      "The shape of test labels: (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of Training images: {images.shape}')\n",
    "print(f'The shape of Training labels: {labels.shape}')\n",
    "print(f'The shape of test images: {test_images.shape}')\n",
    "print(f'The shape of test labels: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization\n",
    "\n",
    "- **Layer Definitions:**\n",
    "    - `HIDDEN_LAYER_SIZE = 100`: Number of neurons in the hidden layer.\n",
    "    - `OUTPUT_LAYER_SIZE = 10`: Number of neurons in the output layer (matching 10 digits in MNIST).\n",
    "    - `INPUT_LAYER_SIZE = images.shape[1]`: Number of input features (784 pixels for MNIST images).\n",
    "- **Model Weights and Biases:**\n",
    "    - `W1`: Weights connecting input layer to hidden layer (784x100 matrix).\n",
    "    - `b1`: Biases for hidden layer neurons (1x100 vector).\n",
    "    - `W2`: Weights connecting hidden layer to output layer (100x10 matrix).\n",
    "    - `b2`: Biases for output layer neurons (1x10 vector).\n",
    "- **Random Initialization:**\n",
    "    - Weights are initialized with small random values between -1 and 1 for better learning.\n",
    "    - Biases are initialized to zero.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- Creates a basic neural network model with one hidden layer, ready for training on the prepared MNIST data.\n",
    "```**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_SIZE = 100\n",
    "OUTPUT_LAYER_SIZE = 10\n",
    "INPUT_LAYER_SIZE = images.shape[1]\n",
    "model = {\n",
    "    'W1': 2 * np.random.random((INPUT_LAYER_SIZE, HIDDEN_LAYER_SIZE)) - 1, # 784 x HIDDEN_LAYER_SIZE\n",
    "    'b1': np.zeros((1, HIDDEN_LAYER_SIZE)), # 1 x HIDDEN_LAYER_SIZE\n",
    "    'W2': 2 * np.random.random((HIDDEN_LAYER_SIZE, OUTPUT_LAYER_SIZE)) - 1, # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE\n",
    "    'b2': np.zeros((1, OUTPUT_LAYER_SIZE)) # 1 x OUTPUT_LAYER_SIZE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "**Defined Functions:**\n",
    "\n",
    "- **`sigmoid(x)`:**\n",
    "    - S-shaped curve that maps input values between 0 and 1.\n",
    "    - Commonly used in output layers for binary classification.\n",
    "    - `np.clip(x, -50, 50)` prevents numerical overflow.\n",
    "- **`sigmoid_derivative(x)`:**\n",
    "    - Calculates the derivative of the sigmoid function, used for backpropagation.\n",
    "- **`relu(x)`:**\n",
    "    - Rectified Linear Unit, outputs 0 for negative inputs and the input value itself for positive inputs.\n",
    "    - Promotes sparsity and helps prevent vanishing gradients.\n",
    "- **`relu2deriv(output)`:**\n",
    "    - Derivative of ReLU, used for backpropagation.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- These functions introduce non-linearity into neural networks, enabling them to learn complex patterns and decision boundaries.\n",
    "- They are essential for the training process, as they determine how neurons transform their inputs into outputs and how errors are propagated back to adjust weights and biases.\n",
    "```**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = np.clip(x, -50, 50)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "def relu2deriv(output):\n",
    "    return output > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **L1 Regularization (Lasso):**\n",
    "\n",
    "**Theory:**\n",
    "\n",
    "* L1 regularization, also known as Lasso regularization, adds a penalty term to the cost function that is proportional to the absolute values of the weights.\n",
    "* The goal is to prevent some weights from becoming too large and drive them towards zero.\n",
    "* The regularization term is the sum of the absolute values of the weights multiplied by a regularization parameter (λ):\n",
    "\n",
    "        \n",
    "        L1_term = λ * ∑ᵢⱼ |Wᵢⱼ|\n",
    "        \n",
    "\n",
    "* Where:\n",
    "    * λ is the regularization parameter.\n",
    "    * Wᵢⱼ represents an individual weight in the weight matrix.\n",
    "\n",
    "**Implementation in train_mnist:**\n",
    "\n",
    "* For each weight matrix W, update it using the following term for L1 regularization:\n",
    "\n",
    "        \n",
    "        W -= learning_rate * (gradient + (λ * sign(W)))\n",
    "        \n",
    "\n",
    "* Here, `sign(W)` represents the element-wise sign function, What it does:\n",
    "\n",
    "It takes a matrix W as input and returns a matrix of the same shape, where each element has been replaced with its sign (positive, negative, or zero).\n",
    "It does this by applying the sign function to each element individually.\n",
    "\n",
    "        Sign function definition:\n",
    "\n",
    "        For positive numbers: sign(x) = 1\n",
    "        For negative numbers: sign(x) = -1\n",
    "        For zero: sign(x) = 0\n",
    "\n",
    "**This term helps to shrink some of the weights towards zero during each update, effectively applying L1 regularization**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L2 Regularization (Ridge):**\n",
    "\n",
    "**Theory:**\n",
    "\n",
    "* L2 regularization, also known as Ridge regularization, adds a penalty term to the cost function that is proportional to the square of the weights.\n",
    "* The goal is to prevent some weights from becoming too large.\n",
    "* The regularization term is the sum of the squared values of the weights multiplied by a regularization parameter (λ):\n",
    "\n",
    "        \n",
    "        L2_term = λ * ∑ᵢⱼ (Wᵢⱼ)²\n",
    "        \n",
    "\n",
    "* Where:\n",
    "    * λ is the regularization parameter.\n",
    "    * Wᵢⱼ represents an individual weight in the weight matrix.\n",
    "\n",
    "**Implementation in train_mnist:**\n",
    "\n",
    "* For each weight matrix W, update it using the following term for L2 regularization:\n",
    "\n",
    "        \n",
    "        W -= learning_rate * (gradient + (λ * W))\n",
    "        \n",
    "\n",
    "* Here, `λ * W` adds a regularization term that is proportional to the weights themselves.\n",
    "* This term penalizes large weights and helps prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "* Both L1 and L2 regularization aim to prevent overfitting by adding penalty terms to the cost function that discourage large weights.\n",
    "* L1 tends to produce sparse weight matrices, encouraging some weights to become exactly zero.\n",
    "* L2 generally results in smaller but non-zero weights.\n",
    "* The choice between L1 and L2 regularization depends on the specific characteristics of the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Explaination of the `train_mnist` function:**\n",
    "\n",
    "**1. Function Purpose:**\n",
    "- Trains a neural network model on the MNIST dataset using mini-batch gradient descent.\n",
    "\n",
    "**2. Parameters:**\n",
    "- `images`: Input images (array of shape `(num_samples, 784)`).\n",
    "- `labels`: True labels (array of shape `(num_samples, OUTPUT_LAYER_SIZE)`).\n",
    "- `model`: Dictionary containing model weights and biases.\n",
    "- `lr`: Learning rate (default: 0.01).\n",
    "- `regularization`: Type of regularization to apply (None, 'L1', or 'L2', default: None).\n",
    "- `reg_lambda`: Regularization strength (default: 0.001).\n",
    "- `decay_rate`: Learning rate decay rate (default: 0.95).\n",
    "- `mini_batch_size`: Size of mini-batches (default: 128).\n",
    "\n",
    "**3. Steps:**\n",
    "\n",
    "1. **Mini-Batch Loop:**\n",
    "   - Iterates through the dataset in mini-batches.\n",
    "2. **Extract Mini-Batch:**\n",
    "   - Gets a subset of images and labels for the current mini-batch.\n",
    "3. **Forward Pass:**\n",
    "   - Calculates outputs for the mini-batch using the model.\n",
    "   - Applies ReLU in the hidden layer and sigmoid in the output layer.\n",
    "4. **Calculate Error:**\n",
    "   - Computes the difference between predicted outputs and true labels.\n",
    "5. **Backpropagation:**\n",
    "   - Calculates error gradients for the output and hidden layers.\n",
    "   - Uses derivatives of ReLU and sigmoid functions.\n",
    "6. **Weights Update:**\n",
    "   - Adjusts model weights and biases based on the gradients and learning rate.\n",
    "   - Incorporates regularization (L1 or L2) if specified.\n",
    "7. **Learning Rate Decay:**\n",
    "   - Decreases the learning rate after each mini-batch to aid convergence.\n",
    "8. **Return Updated Model:**\n",
    "   - Returns the model with updated weights and biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(images, labels, model, lr=0.01, regularization=None, reg_lambda=0.001, decay_rate=0.95, mini_batch_size=128):\n",
    "    num_samples = len(images)\n",
    "    \n",
    "    for i in range(0, num_samples, mini_batch_size):\n",
    "        # Extract mini-batch\n",
    "        batch_images = images[i:i+mini_batch_size] \n",
    "        batch_labels = labels[i:i+mini_batch_size] \n",
    "        \n",
    "        # Forward pass\n",
    "        hidden_layer = relu(batch_images.dot(model['W1']) + model['b1']) # BATCHSIZE x 784 * 784 x HIDDEN_LAYER_SIZE = BATCHSIZE x HIDDEN_LAYER_SIZE\n",
    "        output_layer = sigmoid(hidden_layer.dot(model['W2']) + model['b2']) # BATCHSIZE x HIDDEN_LAYER_SIZE * HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE = BATCHSIZE x OUTPUT_LAYER_SIZE\n",
    "\n",
    "        # Calculate the error/loss\n",
    "        error = output_layer - batch_labels # BATCHSIZE x OUTPUT_LAYER_SIZE # calculates the pure error, or loss, which is used for computing derivatives in backpropagation\n",
    "\n",
    "        # Backpropagation\n",
    "        output_layer_delta = error * sigmoid_derivative(output_layer) # BATCHSIZE x OUTPUT_LAYER_SIZE\n",
    "        hidden_layer_delta = output_layer_delta.dot(model['W2'].T) * relu2deriv(hidden_layer) # BATCHSIZE x OUTPUT_LAYER_SIZE * OUTPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE = BATCHSIZE x HIDDEN_LAYER_SIZE\n",
    "\n",
    "        # Weights Update\n",
    "        if regularization == 'L1':\n",
    "            model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta)) + reg_lambda * np.sign(model['W2']) # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE \n",
    "            model['W1'] -= lr * (batch_images.T.dot(hidden_layer_delta)) + reg_lambda * np.sign(model['W1']) # INPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE \n",
    "        elif regularization == 'L2':\n",
    "            model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta)) + reg_lambda * model['W2'] # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE\n",
    "            model['W1'] -= lr * (batch_images.T.dot(hidden_layer_delta)) + reg_lambda * model['W1'] # INPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE\n",
    "        else:\n",
    "            model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta)) # HIDDEN_LAYER_SIZE x OUTPUT_LAYER_SIZE\n",
    "            model['W1'] -= lr * (batch_images.T.dot(hidden_layer_delta)) # INPUT_LAYER_SIZE x HIDDEN_LAYER_SIZE\n",
    "\n",
    "        model['b2'] -= lr * np.mean(output_layer_delta) # 1 x HIDDEN_LAYER_SIZE\n",
    "        model['b1'] -= lr * np.mean(hidden_layer_delta) # 1 x OUTPUT_LAYER_SIZE\n",
    "\n",
    "    # Learning rate decay\n",
    "    lr *= decay_rate\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Implementation of the prediction and evaluation function**\n",
    "\n",
    "**1. `model_prediction(model, X)`:**\n",
    "\n",
    "- **Purpose:** Generates predictions for given inputs using the model.\n",
    "- **Steps:**\n",
    "    1. **Calculate hidden layer outputs:** Applies ReLU activation to the weighted sum of inputs and hidden layer weights (`model['W1']`) plus biases (`model['b1']`).\n",
    "    2. **Calculate output layer outputs:** Applies sigmoid activation to the weighted sum of hidden layer outputs and output layer weights (`model['W2']`) plus biases (`model['b2']`).\n",
    "    3. **Return output layer:** Returns raw output scores from the output layer, representing predicted probabilities (or confidence scores) for each class.\n",
    "\n",
    "**2. `evaluate_accuracy(model, X, y_true)`:**\n",
    "\n",
    "- **Purpose:** Calculates overall accuracy of the model's predictions on a dataset.\n",
    "- **Steps:**\n",
    "    1. **Generate model predictions:** Calls `model_prediction` to get predictions for all inputs in `X`.\n",
    "    2. **Extract predicted labels:** Finds the index of the highest-scoring class for each prediction using `np.argmax`.\n",
    "    3. **Extract true labels:** Extracts true class labels from `y_true` (assuming one-hot encoded).\n",
    "    4. **Compare predictions and true labels:** Calculates the proportion of correct predictions.\n",
    "    5. **Return accuracy:** Returns the overall accuracy as a percentage.\n",
    "\n",
    "**3. `evaluate_accuracy_one_sample(model, X, y_true)`:**\n",
    "\n",
    "- **Purpose:** Evaluates accuracy for a single sample (input and true label).\n",
    "- **Steps:**\n",
    "    1. **Generate model prediction:** Calls `model_prediction` for the single input `X`.\n",
    "    2. **Extract predicted label:** Finds the index of the highest-scoring class in the prediction.\n",
    "    3. **Extract true label:** Extracts the true class label from `y_true`.\n",
    "    4. **Compare prediction and true label:** Checks if they match.\n",
    "    5. **Return accuracy:** Returns `True` if prediction is correct, `False` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, X):\n",
    "    hidden_layer = relu(X.dot(model['W1']) + model['b1']) \n",
    "    output_layer = sigmoid(hidden_layer.dot(model['W2']) + model['b2']) \n",
    "    return output_layer\n",
    "\n",
    "def evaluate_accuracy(model, X, y_true):\n",
    "    predictions = model_prediction(model, X)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    return accuracy\n",
    "def evaluate_accuracy_one_sample(model, X, y_true):\n",
    "    predictions = model_prediction(model, X)\n",
    "    predicted_labels = np.argmax(predictions)\n",
    "    true_labels = np.argmax(y_true)\n",
    "    \n",
    "    accuracy = predicted_labels == true_labels\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Training Setup:**\n",
    "\n",
    "- **Lists for Accuracies:** `train_accuracies` and `val_accuracies` store accuracies from each epoch for tracking progress.\n",
    "- **Early Stopping:**\n",
    "    - `no_improvement_count` tracks epochs without validation improvement.\n",
    "    - `patience` sets the maximum number of epochs without improvement before stopping (50 in this case).\n",
    "    - `best_val_acc` stores the best validation accuracy achieved so far.\n",
    "\n",
    "**2. Training Loop:**\n",
    "\n",
    "- **Iterates up to 500 epochs:** Runs a maximum of 500 training iterations.\n",
    "- **Model Training:**\n",
    "    - Calls the `train_mnist` function to train the model on the training data (`images`, `labels`).\n",
    "        - Uses hyperparameters: learning rate (`lr`), regularization type (`regularization`), regularization strength (`reg_lambda`), and mini-batch size (`mini_batch_size`).\n",
    "- **Accuracy Calculation:**\n",
    "    - Evaluates accuracy on both training and validation sets using `evaluate_accuracy`.\n",
    "- **Storing Accuracies:** Appends accuracies to their respective lists for plotting.\n",
    "- **Printing Progress:** Prints epoch number and accuracies.\n",
    "- **Best Model Tracking:**\n",
    "    - If validation accuracy improves, updates `best_val_acc`, copies model weights to `best_model`, and resets `no_improvement_count`.\n",
    "- **Early Stopping:**\n",
    "    - If validation accuracy hasn't improved for `patience` epochs, stops training and prints a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.8158, Val Accuracy: 0.7917\n",
      "Epoch 2, Train Accuracy: 0.8573, Val Accuracy: 0.8327\n",
      "Epoch 3, Train Accuracy: 0.8806, Val Accuracy: 0.8572\n",
      "Epoch 4, Train Accuracy: 0.8960, Val Accuracy: 0.8753\n",
      "Epoch 5, Train Accuracy: 0.9065, Val Accuracy: 0.8870\n",
      "Epoch 6, Train Accuracy: 0.9138, Val Accuracy: 0.8963\n",
      "Epoch 7, Train Accuracy: 0.9192, Val Accuracy: 0.9018\n",
      "Epoch 8, Train Accuracy: 0.9241, Val Accuracy: 0.9087\n",
      "Epoch 9, Train Accuracy: 0.9276, Val Accuracy: 0.9132\n",
      "Epoch 10, Train Accuracy: 0.9297, Val Accuracy: 0.9172\n",
      "Epoch 11, Train Accuracy: 0.9318, Val Accuracy: 0.9195\n",
      "Epoch 12, Train Accuracy: 0.9336, Val Accuracy: 0.9208\n",
      "Epoch 13, Train Accuracy: 0.9348, Val Accuracy: 0.9228\n",
      "Epoch 14, Train Accuracy: 0.9358, Val Accuracy: 0.9240\n",
      "Epoch 15, Train Accuracy: 0.9370, Val Accuracy: 0.9250\n",
      "Epoch 16, Train Accuracy: 0.9381, Val Accuracy: 0.9262\n",
      "Epoch 17, Train Accuracy: 0.9390, Val Accuracy: 0.9258\n",
      "Epoch 18, Train Accuracy: 0.9397, Val Accuracy: 0.9267\n",
      "Epoch 19, Train Accuracy: 0.9401, Val Accuracy: 0.9267\n",
      "Epoch 20, Train Accuracy: 0.9405, Val Accuracy: 0.9267\n",
      "Epoch 21, Train Accuracy: 0.9410, Val Accuracy: 0.9277\n",
      "Epoch 22, Train Accuracy: 0.9413, Val Accuracy: 0.9278\n",
      "Epoch 23, Train Accuracy: 0.9417, Val Accuracy: 0.9288\n",
      "Epoch 24, Train Accuracy: 0.9421, Val Accuracy: 0.9290\n",
      "Epoch 25, Train Accuracy: 0.9423, Val Accuracy: 0.9293\n",
      "Epoch 26, Train Accuracy: 0.9428, Val Accuracy: 0.9300\n",
      "Epoch 27, Train Accuracy: 0.9430, Val Accuracy: 0.9307\n",
      "Epoch 28, Train Accuracy: 0.9431, Val Accuracy: 0.9313\n",
      "Epoch 29, Train Accuracy: 0.9433, Val Accuracy: 0.9312\n",
      "Epoch 30, Train Accuracy: 0.9435, Val Accuracy: 0.9312\n",
      "Epoch 31, Train Accuracy: 0.9437, Val Accuracy: 0.9312\n",
      "Epoch 32, Train Accuracy: 0.9438, Val Accuracy: 0.9313\n",
      "Epoch 33, Train Accuracy: 0.9440, Val Accuracy: 0.9313\n",
      "Epoch 34, Train Accuracy: 0.9441, Val Accuracy: 0.9313\n",
      "Epoch 35, Train Accuracy: 0.9442, Val Accuracy: 0.9312\n",
      "Epoch 36, Train Accuracy: 0.9443, Val Accuracy: 0.9317\n",
      "Epoch 37, Train Accuracy: 0.9444, Val Accuracy: 0.9318\n",
      "Epoch 38, Train Accuracy: 0.9445, Val Accuracy: 0.9322\n",
      "Epoch 39, Train Accuracy: 0.9446, Val Accuracy: 0.9320\n",
      "Epoch 40, Train Accuracy: 0.9447, Val Accuracy: 0.9322\n",
      "Epoch 41, Train Accuracy: 0.9448, Val Accuracy: 0.9328\n",
      "Epoch 42, Train Accuracy: 0.9448, Val Accuracy: 0.9327\n",
      "Epoch 43, Train Accuracy: 0.9448, Val Accuracy: 0.9325\n",
      "Epoch 44, Train Accuracy: 0.9449, Val Accuracy: 0.9327\n",
      "Epoch 45, Train Accuracy: 0.9450, Val Accuracy: 0.9328\n",
      "Epoch 46, Train Accuracy: 0.9450, Val Accuracy: 0.9328\n",
      "Epoch 47, Train Accuracy: 0.9452, Val Accuracy: 0.9330\n",
      "Epoch 48, Train Accuracy: 0.9453, Val Accuracy: 0.9328\n",
      "Epoch 49, Train Accuracy: 0.9455, Val Accuracy: 0.9328\n",
      "Epoch 50, Train Accuracy: 0.9456, Val Accuracy: 0.9330\n",
      "Epoch 51, Train Accuracy: 0.9456, Val Accuracy: 0.9328\n",
      "Epoch 52, Train Accuracy: 0.9457, Val Accuracy: 0.9330\n",
      "Epoch 53, Train Accuracy: 0.9458, Val Accuracy: 0.9327\n",
      "Epoch 54, Train Accuracy: 0.9458, Val Accuracy: 0.9330\n",
      "Epoch 55, Train Accuracy: 0.9459, Val Accuracy: 0.9332\n",
      "Epoch 56, Train Accuracy: 0.9460, Val Accuracy: 0.9335\n",
      "Epoch 57, Train Accuracy: 0.9460, Val Accuracy: 0.9335\n",
      "Epoch 58, Train Accuracy: 0.9461, Val Accuracy: 0.9337\n",
      "Epoch 59, Train Accuracy: 0.9462, Val Accuracy: 0.9338\n",
      "Epoch 60, Train Accuracy: 0.9462, Val Accuracy: 0.9338\n",
      "Epoch 61, Train Accuracy: 0.9463, Val Accuracy: 0.9338\n",
      "Epoch 62, Train Accuracy: 0.9464, Val Accuracy: 0.9340\n",
      "Epoch 63, Train Accuracy: 0.9464, Val Accuracy: 0.9343\n",
      "Epoch 64, Train Accuracy: 0.9464, Val Accuracy: 0.9347\n",
      "Epoch 65, Train Accuracy: 0.9465, Val Accuracy: 0.9352\n",
      "Epoch 66, Train Accuracy: 0.9465, Val Accuracy: 0.9352\n",
      "Epoch 67, Train Accuracy: 0.9465, Val Accuracy: 0.9352\n",
      "Epoch 68, Train Accuracy: 0.9466, Val Accuracy: 0.9353\n",
      "Epoch 69, Train Accuracy: 0.9466, Val Accuracy: 0.9353\n",
      "Epoch 70, Train Accuracy: 0.9466, Val Accuracy: 0.9355\n",
      "Epoch 71, Train Accuracy: 0.9467, Val Accuracy: 0.9355\n",
      "Epoch 72, Train Accuracy: 0.9467, Val Accuracy: 0.9357\n",
      "Epoch 73, Train Accuracy: 0.9467, Val Accuracy: 0.9355\n",
      "Epoch 74, Train Accuracy: 0.9467, Val Accuracy: 0.9357\n",
      "Epoch 75, Train Accuracy: 0.9468, Val Accuracy: 0.9358\n",
      "Epoch 76, Train Accuracy: 0.9469, Val Accuracy: 0.9358\n",
      "Epoch 77, Train Accuracy: 0.9469, Val Accuracy: 0.9360\n",
      "Epoch 78, Train Accuracy: 0.9470, Val Accuracy: 0.9360\n",
      "Epoch 79, Train Accuracy: 0.9469, Val Accuracy: 0.9360\n",
      "Epoch 80, Train Accuracy: 0.9470, Val Accuracy: 0.9362\n",
      "Epoch 81, Train Accuracy: 0.9470, Val Accuracy: 0.9360\n",
      "Epoch 82, Train Accuracy: 0.9470, Val Accuracy: 0.9360\n",
      "Epoch 83, Train Accuracy: 0.9470, Val Accuracy: 0.9360\n",
      "Epoch 84, Train Accuracy: 0.9470, Val Accuracy: 0.9360\n",
      "Epoch 85, Train Accuracy: 0.9471, Val Accuracy: 0.9360\n",
      "Epoch 86, Train Accuracy: 0.9471, Val Accuracy: 0.9360\n",
      "Epoch 87, Train Accuracy: 0.9472, Val Accuracy: 0.9360\n",
      "Epoch 88, Train Accuracy: 0.9473, Val Accuracy: 0.9362\n",
      "Epoch 89, Train Accuracy: 0.9472, Val Accuracy: 0.9365\n",
      "Epoch 90, Train Accuracy: 0.9474, Val Accuracy: 0.9365\n",
      "Epoch 91, Train Accuracy: 0.9474, Val Accuracy: 0.9365\n",
      "Epoch 92, Train Accuracy: 0.9474, Val Accuracy: 0.9365\n",
      "Epoch 93, Train Accuracy: 0.9474, Val Accuracy: 0.9363\n",
      "Epoch 94, Train Accuracy: 0.9474, Val Accuracy: 0.9363\n",
      "Epoch 95, Train Accuracy: 0.9474, Val Accuracy: 0.9363\n",
      "Epoch 96, Train Accuracy: 0.9474, Val Accuracy: 0.9365\n",
      "Epoch 97, Train Accuracy: 0.9475, Val Accuracy: 0.9365\n",
      "Epoch 98, Train Accuracy: 0.9475, Val Accuracy: 0.9365\n",
      "Epoch 99, Train Accuracy: 0.9475, Val Accuracy: 0.9365\n",
      "Epoch 100, Train Accuracy: 0.9475, Val Accuracy: 0.9367\n",
      "Epoch 101, Train Accuracy: 0.9476, Val Accuracy: 0.9365\n",
      "Epoch 102, Train Accuracy: 0.9476, Val Accuracy: 0.9365\n",
      "Epoch 103, Train Accuracy: 0.9476, Val Accuracy: 0.9365\n",
      "Epoch 104, Train Accuracy: 0.9476, Val Accuracy: 0.9365\n",
      "Epoch 105, Train Accuracy: 0.9476, Val Accuracy: 0.9365\n",
      "Epoch 106, Train Accuracy: 0.9476, Val Accuracy: 0.9365\n",
      "Epoch 107, Train Accuracy: 0.9476, Val Accuracy: 0.9368\n",
      "Epoch 108, Train Accuracy: 0.9477, Val Accuracy: 0.9370\n",
      "Epoch 109, Train Accuracy: 0.9477, Val Accuracy: 0.9370\n",
      "Epoch 110, Train Accuracy: 0.9477, Val Accuracy: 0.9370\n",
      "Epoch 111, Train Accuracy: 0.9477, Val Accuracy: 0.9370\n",
      "Epoch 112, Train Accuracy: 0.9477, Val Accuracy: 0.9368\n",
      "Epoch 113, Train Accuracy: 0.9477, Val Accuracy: 0.9368\n",
      "Epoch 114, Train Accuracy: 0.9478, Val Accuracy: 0.9368\n",
      "Epoch 115, Train Accuracy: 0.9477, Val Accuracy: 0.9368\n",
      "Epoch 116, Train Accuracy: 0.9478, Val Accuracy: 0.9368\n",
      "Epoch 117, Train Accuracy: 0.9478, Val Accuracy: 0.9370\n",
      "Epoch 118, Train Accuracy: 0.9477, Val Accuracy: 0.9368\n",
      "Epoch 119, Train Accuracy: 0.9478, Val Accuracy: 0.9370\n",
      "Epoch 120, Train Accuracy: 0.9478, Val Accuracy: 0.9370\n",
      "Epoch 121, Train Accuracy: 0.9478, Val Accuracy: 0.9370\n",
      "Epoch 122, Train Accuracy: 0.9478, Val Accuracy: 0.9368\n",
      "Epoch 123, Train Accuracy: 0.9479, Val Accuracy: 0.9368\n",
      "Epoch 124, Train Accuracy: 0.9479, Val Accuracy: 0.9367\n",
      "Epoch 125, Train Accuracy: 0.9479, Val Accuracy: 0.9367\n",
      "Epoch 126, Train Accuracy: 0.9479, Val Accuracy: 0.9367\n",
      "Epoch 127, Train Accuracy: 0.9479, Val Accuracy: 0.9368\n",
      "Epoch 128, Train Accuracy: 0.9479, Val Accuracy: 0.9368\n",
      "Epoch 129, Train Accuracy: 0.9480, Val Accuracy: 0.9368\n",
      "Epoch 130, Train Accuracy: 0.9480, Val Accuracy: 0.9368\n",
      "Epoch 131, Train Accuracy: 0.9480, Val Accuracy: 0.9370\n",
      "Epoch 132, Train Accuracy: 0.9480, Val Accuracy: 0.9370\n",
      "Epoch 133, Train Accuracy: 0.9480, Val Accuracy: 0.9372\n",
      "Epoch 134, Train Accuracy: 0.9480, Val Accuracy: 0.9372\n",
      "Epoch 135, Train Accuracy: 0.9480, Val Accuracy: 0.9370\n",
      "Epoch 136, Train Accuracy: 0.9481, Val Accuracy: 0.9372\n",
      "Epoch 137, Train Accuracy: 0.9480, Val Accuracy: 0.9370\n",
      "Epoch 138, Train Accuracy: 0.9480, Val Accuracy: 0.9370\n",
      "Epoch 139, Train Accuracy: 0.9481, Val Accuracy: 0.9370\n",
      "Epoch 140, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 141, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 142, Train Accuracy: 0.9481, Val Accuracy: 0.9370\n",
      "Epoch 143, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 144, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 145, Train Accuracy: 0.9482, Val Accuracy: 0.9367\n",
      "Epoch 146, Train Accuracy: 0.9482, Val Accuracy: 0.9367\n",
      "Epoch 147, Train Accuracy: 0.9482, Val Accuracy: 0.9367\n",
      "Epoch 148, Train Accuracy: 0.9482, Val Accuracy: 0.9365\n",
      "Epoch 149, Train Accuracy: 0.9483, Val Accuracy: 0.9367\n",
      "Epoch 150, Train Accuracy: 0.9482, Val Accuracy: 0.9368\n",
      "Epoch 151, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 152, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 153, Train Accuracy: 0.9482, Val Accuracy: 0.9372\n",
      "Epoch 154, Train Accuracy: 0.9482, Val Accuracy: 0.9373\n",
      "Epoch 155, Train Accuracy: 0.9482, Val Accuracy: 0.9372\n",
      "Epoch 156, Train Accuracy: 0.9482, Val Accuracy: 0.9372\n",
      "Epoch 157, Train Accuracy: 0.9482, Val Accuracy: 0.9372\n",
      "Epoch 158, Train Accuracy: 0.9482, Val Accuracy: 0.9372\n",
      "Epoch 159, Train Accuracy: 0.9482, Val Accuracy: 0.9370\n",
      "Epoch 160, Train Accuracy: 0.9483, Val Accuracy: 0.9372\n",
      "Epoch 161, Train Accuracy: 0.9483, Val Accuracy: 0.9370\n",
      "Epoch 162, Train Accuracy: 0.9482, Val Accuracy: 0.9372\n",
      "Epoch 163, Train Accuracy: 0.9483, Val Accuracy: 0.9370\n",
      "Epoch 164, Train Accuracy: 0.9483, Val Accuracy: 0.9372\n",
      "Epoch 165, Train Accuracy: 0.9483, Val Accuracy: 0.9375\n",
      "Epoch 166, Train Accuracy: 0.9483, Val Accuracy: 0.9372\n",
      "Epoch 167, Train Accuracy: 0.9484, Val Accuracy: 0.9373\n",
      "Epoch 168, Train Accuracy: 0.9483, Val Accuracy: 0.9373\n",
      "Epoch 169, Train Accuracy: 0.9484, Val Accuracy: 0.9375\n",
      "Epoch 170, Train Accuracy: 0.9484, Val Accuracy: 0.9375\n",
      "Epoch 171, Train Accuracy: 0.9484, Val Accuracy: 0.9375\n",
      "Epoch 172, Train Accuracy: 0.9484, Val Accuracy: 0.9373\n",
      "Epoch 173, Train Accuracy: 0.9484, Val Accuracy: 0.9373\n",
      "Epoch 174, Train Accuracy: 0.9484, Val Accuracy: 0.9372\n",
      "Epoch 175, Train Accuracy: 0.9484, Val Accuracy: 0.9373\n",
      "Epoch 176, Train Accuracy: 0.9484, Val Accuracy: 0.9372\n",
      "Epoch 177, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 178, Train Accuracy: 0.9484, Val Accuracy: 0.9372\n",
      "Epoch 179, Train Accuracy: 0.9484, Val Accuracy: 0.9375\n",
      "Epoch 180, Train Accuracy: 0.9484, Val Accuracy: 0.9373\n",
      "Epoch 181, Train Accuracy: 0.9484, Val Accuracy: 0.9377\n",
      "Epoch 182, Train Accuracy: 0.9484, Val Accuracy: 0.9372\n",
      "Epoch 183, Train Accuracy: 0.9484, Val Accuracy: 0.9373\n",
      "Epoch 184, Train Accuracy: 0.9484, Val Accuracy: 0.9375\n",
      "Epoch 185, Train Accuracy: 0.9484, Val Accuracy: 0.9375\n",
      "Epoch 186, Train Accuracy: 0.9484, Val Accuracy: 0.9372\n",
      "Epoch 187, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 188, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 189, Train Accuracy: 0.9485, Val Accuracy: 0.9372\n",
      "Epoch 190, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 191, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 192, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 193, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 194, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 195, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 196, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 197, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 198, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 199, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 200, Train Accuracy: 0.9485, Val Accuracy: 0.9373\n",
      "Epoch 201, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 202, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 203, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 204, Train Accuracy: 0.9485, Val Accuracy: 0.9375\n",
      "Epoch 205, Train Accuracy: 0.9485, Val Accuracy: 0.9377\n",
      "Epoch 206, Train Accuracy: 0.9485, Val Accuracy: 0.9378\n",
      "Epoch 207, Train Accuracy: 0.9485, Val Accuracy: 0.9377\n",
      "Epoch 208, Train Accuracy: 0.9485, Val Accuracy: 0.9378\n",
      "Epoch 209, Train Accuracy: 0.9485, Val Accuracy: 0.9378\n",
      "Epoch 210, Train Accuracy: 0.9485, Val Accuracy: 0.9378\n",
      "Epoch 211, Train Accuracy: 0.9485, Val Accuracy: 0.9380\n",
      "Epoch 212, Train Accuracy: 0.9486, Val Accuracy: 0.9378\n",
      "Epoch 213, Train Accuracy: 0.9486, Val Accuracy: 0.9380\n",
      "Epoch 214, Train Accuracy: 0.9486, Val Accuracy: 0.9378\n",
      "Epoch 215, Train Accuracy: 0.9486, Val Accuracy: 0.9378\n",
      "Epoch 216, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 217, Train Accuracy: 0.9485, Val Accuracy: 0.9380\n",
      "Epoch 218, Train Accuracy: 0.9486, Val Accuracy: 0.9380\n",
      "Epoch 219, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 220, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 221, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 222, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 223, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 224, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 225, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 226, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 227, Train Accuracy: 0.9486, Val Accuracy: 0.9378\n",
      "Epoch 228, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 229, Train Accuracy: 0.9486, Val Accuracy: 0.9383\n",
      "Epoch 230, Train Accuracy: 0.9486, Val Accuracy: 0.9380\n",
      "Epoch 231, Train Accuracy: 0.9486, Val Accuracy: 0.9380\n",
      "Epoch 232, Train Accuracy: 0.9485, Val Accuracy: 0.9382\n",
      "Epoch 233, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 234, Train Accuracy: 0.9486, Val Accuracy: 0.9383\n",
      "Epoch 235, Train Accuracy: 0.9486, Val Accuracy: 0.9380\n",
      "Epoch 236, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 237, Train Accuracy: 0.9486, Val Accuracy: 0.9380\n",
      "Epoch 238, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 239, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 240, Train Accuracy: 0.9487, Val Accuracy: 0.9382\n",
      "Epoch 241, Train Accuracy: 0.9487, Val Accuracy: 0.9380\n",
      "Epoch 242, Train Accuracy: 0.9486, Val Accuracy: 0.9382\n",
      "Epoch 243, Train Accuracy: 0.9487, Val Accuracy: 0.9383\n",
      "Epoch 244, Train Accuracy: 0.9487, Val Accuracy: 0.9383\n",
      "Epoch 245, Train Accuracy: 0.9487, Val Accuracy: 0.9383\n",
      "Epoch 246, Train Accuracy: 0.9487, Val Accuracy: 0.9383\n",
      "Epoch 247, Train Accuracy: 0.9487, Val Accuracy: 0.9382\n",
      "Epoch 248, Train Accuracy: 0.9487, Val Accuracy: 0.9383\n",
      "Epoch 249, Train Accuracy: 0.9487, Val Accuracy: 0.9382\n",
      "Epoch 250, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 251, Train Accuracy: 0.9487, Val Accuracy: 0.9382\n",
      "Epoch 252, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 253, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 254, Train Accuracy: 0.9488, Val Accuracy: 0.9382\n",
      "Epoch 255, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 256, Train Accuracy: 0.9488, Val Accuracy: 0.9382\n",
      "Epoch 257, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 258, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 259, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 260, Train Accuracy: 0.9487, Val Accuracy: 0.9385\n",
      "Epoch 261, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 262, Train Accuracy: 0.9487, Val Accuracy: 0.9383\n",
      "Epoch 263, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 264, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 265, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 266, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 267, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 268, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 269, Train Accuracy: 0.9489, Val Accuracy: 0.9383\n",
      "Epoch 270, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 271, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 272, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 273, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 274, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 275, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 276, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 277, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 278, Train Accuracy: 0.9489, Val Accuracy: 0.9382\n",
      "Epoch 279, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 280, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 281, Train Accuracy: 0.9489, Val Accuracy: 0.9383\n",
      "Epoch 282, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 283, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 284, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 285, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 286, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 287, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 288, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 289, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 290, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 291, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 292, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 293, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 294, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 295, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 296, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 297, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 298, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 299, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 300, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 301, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 302, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 303, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 304, Train Accuracy: 0.9488, Val Accuracy: 0.9383\n",
      "Epoch 305, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 306, Train Accuracy: 0.9488, Val Accuracy: 0.9385\n",
      "Epoch 307, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 308, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 309, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 310, Train Accuracy: 0.9489, Val Accuracy: 0.9385\n",
      "Epoch 311, Train Accuracy: 0.9488, Val Accuracy: 0.9387\n",
      "Epoch 312, Train Accuracy: 0.9489, Val Accuracy: 0.9387\n",
      "Epoch 313, Train Accuracy: 0.9489, Val Accuracy: 0.9387\n",
      "Early stopping: Validation accuracy did not improve for 50 epochs.\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "no_improvement_count = 0\n",
    "patience = 50\n",
    "best_val_acc = 0.0\n",
    "for iteration in range(500):\n",
    "    # Training the model\n",
    "    train_mnist(images, labels, model, lr=0.001, regularization='L2', reg_lambda=0.001, mini_batch_size=512)\n",
    "\n",
    "    # Calculating the accuracies\n",
    "    train_accuracy = evaluate_accuracy(model, images, labels)\n",
    "    val_accuracy = evaluate_accuracy(model, test_images, test_labels)\n",
    "\n",
    "    # Storing the accuracies to plot it\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {iteration + 1}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    # Picking up the best model weights and accuracy\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        best_model = model.copy()\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    if no_improvement_count >= patience:\n",
    "        print(\"Early stopping: Validation accuracy did not improve for 50 epochs.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the accuracies\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy on Validation set is: 94.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model Accuracy on Validation set is: {np.round(best_val_acc * 100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Testing on Remaining Test Set:**\n",
    "- It loops through images not used for validation.\n",
    "- For each image:\n",
    "    - Gets a prediction from the best model.\n",
    "    - Extracts predicted and true labels.\n",
    "    - Stores them as pairs for later analysis.\n",
    "\n",
    "**2. Calculating Accuracy:**\n",
    "- Counts correct predictions using list comprehension.\n",
    "- Divides correct by total to get accuracy.\n",
    "\n",
    "**3. Printing Results:**\n",
    "- Outputs number of correct predictions, total predictions, and accuracy percentage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions count is: 3883 out of 4000\n",
      "The accuracy is: 97.08%\n"
     ]
    }
   ],
   "source": [
    "# Iterating over the rest of the test images that we didnt include in val_set\n",
    "all_preds = []\n",
    "for image in range(len(test_labels), len(test_labels_all)):\n",
    "    test_image = test_images_all[image]\n",
    "    test_label = test_labels_all[image]\n",
    "    predicted_label = model_prediction(best_model, test_image)\n",
    "    predicted_label = np.argmax(predicted_label)\n",
    "    test_label = np.argmax(test_label)\n",
    "    all_preds.append((predicted_label,test_label))\n",
    "\n",
    "correct_predictions = sum(1 for pred, true_label in all_preds if pred == true_label)\n",
    "accuracy = np.round(correct_predictions / len(all_preds) * 100, 2)\n",
    "\n",
    "print(f'Correct predictions count is: {correct_predictions} out of {len(all_preds)}\\nThe accuracy is: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting a random images\n",
    "res = evaluate_accuracy_one_sample(best_model, test_images_all[6123], test_labels_all[6123])\n",
    "res \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label of example 1:\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "Prediction of the model of example 1:\n",
      " [3.66841683e-03 4.28247687e-04 1.00267565e-02 1.35233031e-02\n",
      " 3.71979415e-04 6.53563982e-03 1.47981144e-04 9.91988261e-01\n",
      " 2.93858506e-03 6.39082652e-03]\n",
      "\n",
      "Subtraction of the predection and the actual label example 1:\n",
      " [ 0.00366842  0.00042825  0.01002676  0.0135233   0.00037198  0.00653564\n",
      "  0.00014798 -0.00801174  0.00293859  0.00639083]\n",
      "-------------------------\n",
      "(16, 10)\n",
      "(16, 10)\n"
     ]
    }
   ],
   "source": [
    "# Simulating the error \n",
    "preds = model_prediction(model, test_images[0:16]) # 16x10\n",
    "print(f'Actual Label of example 1:\\n {test_labels[0:16][0]}')\n",
    "print()\n",
    "print(f'Prediction of the model of example 1:\\n {preds[0]}')\n",
    "print()\n",
    "print(f'Subtraction of the predection and the actual label example 1:\\n {(preds - test_labels[0:16])[0]}') # This is the pure error which is we are going to calculate the dervitive according to it\n",
    "print('-------------------------')\n",
    "print((test_labels[0:16]).shape)\n",
    "print((preds.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\n",
      "0.9375\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(preds, axis=1))\n",
    "print(np.argmax(test_labels[0:16], axis=1))\n",
    "print(np.mean(np.argmax(preds, axis=1) == np.argmax(test_labels[0:16], axis=1)))\n",
    "print(np.argmax(preds[0])) # taking a list and returning the index of the greatest number of this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000225\n"
     ]
    }
   ],
   "source": [
    "print(0.0015 * 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((HIDDEN_LAYER_SIZE, 1))\n",
    "test2 = test.reshape(1, -1)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01]\n",
      " [0.01]\n",
      " [0.01]\n",
      " [0.01]\n",
      " [0.01]]\n"
     ]
    }
   ],
   "source": [
    "print(np.sign(np.random.rand(5, 1)) * 0.01) # -1 if x < 0, 0 if x==0, 1 if x > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63. 18.]\n",
      " [26.  5.]]\n",
      "[[63.03 18.05]\n",
      " [26.04  5.06]]\n",
      "[[3. 5.]\n",
      " [4. 6.]]\n",
      "[[2.907 4.932]\n",
      " [3.934 5.935]]\n"
     ]
    }
   ],
   "source": [
    "h = np.array([[4.0, 7.0],\n",
    "              [3.0, 1.0]])\n",
    "\n",
    "delta = np.array([[7.0, 1.0],\n",
    "                  [5.0, 2.0]])\n",
    "\n",
    "w = np.array([[3.0, 5.0],\n",
    "              [4.0, 6.0]])\n",
    "\n",
    "## model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta)) + reg_lambda * model['W2']\n",
    "\n",
    "left = h.dot(delta)\n",
    "\n",
    "print(left) # hidden.dot(output_delta)\n",
    "\n",
    "lambda_w = np.array([[0.03, 0.05],\n",
    "                     [0.04, 0.06]]) # reg_lambda * w = 0.01 * w\n",
    "\n",
    "print(left + lambda_w)\n",
    "print(w)\n",
    "w -= 0.001 * (left) + lambda_w\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "w: [[2.3697 4.8195]\n",
      " [3.7396 5.9494]]\n",
      "Iteration 2:\n",
      "w: [[1.73946303 4.63901805]\n",
      " [3.47922604 5.89880506]]\n",
      "Iteration 3:\n",
      "w: [[1.10928908 4.45855415]\n",
      " [3.21887812 5.84821518]]\n",
      "Iteration 4:\n",
      "w: [[0.47917815 4.27810829]\n",
      " [2.95855623 5.79763036]]\n",
      "Iteration 5:\n",
      "w: [[-0.15086976  4.09768048]\n",
      " [ 2.69826037  5.74705059]]\n"
     ]
    }
   ],
   "source": [
    "#L2 Regularization\n",
    "h = np.array([[4.0, 7.0],\n",
    "             [3.0, 1.0]])\n",
    "\n",
    "delta = np.array([[7.0, 1.0],\n",
    "                 [5.0, 2.0]])\n",
    "\n",
    "w = np.array([[3.0, 5.0],\n",
    "             [4.0, 6.0]])\n",
    "\n",
    "reg_lambda = 0.01  # Regularization parameter\n",
    "learning_rate = 0.01\n",
    "\n",
    "for _ in range(5):\n",
    "   left = h.dot(delta)\n",
    "   lambda_w = reg_lambda * w\n",
    "\n",
    "   w -= learning_rate * (left + lambda_w)\n",
    "   print(f\"Iteration {_+1}:\")\n",
    "   print(f\"w: {w}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "w: [[2.3699 4.8199]\n",
      " [3.7399 5.9499]]\n",
      "Iteration 2:\n",
      "w: [[1.7398 4.6398]\n",
      " [3.4798 5.8998]]\n",
      "Iteration 3:\n",
      "w: [[1.1097 4.4597]\n",
      " [3.2197 5.8497]]\n",
      "Iteration 4:\n",
      "w: [[0.4796 4.2796]\n",
      " [2.9596 5.7996]]\n",
      "Iteration 5:\n",
      "w: [[-0.1505  4.0995]\n",
      " [ 2.6995  5.7495]]\n"
     ]
    }
   ],
   "source": [
    "#L2 Regularization\n",
    "h = np.array([[4.0, 7.0],\n",
    "             [3.0, 1.0]])\n",
    "\n",
    "delta = np.array([[7.0, 1.0],\n",
    "                 [5.0, 2.0]])\n",
    "\n",
    "w = np.array([[3.0, 5.0],\n",
    "             [4.0, 6.0]])\n",
    "\n",
    "reg_lambda = 0.01  # Regularization parameter\n",
    "learning_rate = 0.01\n",
    "\n",
    "for _ in range(5):\n",
    "   left = h.dot(delta)\n",
    "   lambda_w = reg_lambda * np.sign(w)\n",
    "\n",
    "   w -= learning_rate * (left + lambda_w)\n",
    "   print(f\"Iteration {_+1}:\")\n",
    "   print(f\"w: {w}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_mnist(images, labels, model, lr= 0.01, regularization=None, reg_lambda= 0.01):\n",
    "#     # Forward pass\n",
    "#     hidden_layer = relu(images.dot(model['W1']) + model['b1']) # 10000x784 * 784x50 = 10000x50\n",
    "#     output_layer = sigmoid(hidden_layer.dot(model['W2']) + model['b2']) # 10000x50 * 50x9 = 10000x9\n",
    "\n",
    "#     # Calculate the error\n",
    "#     error = output_layer - labels # 10000x9\n",
    "\n",
    "#     # Backpropagation\n",
    "#     output_layer_delta = error * sigmoid_derivative(output_layer) # 10000x9 * 10000x9 = 10000x9\n",
    "#     hidden_layer_delta = output_layer_delta.dot(model['W2'].T) * relu2deriv(hidden_layer) # 10000x9 * 9x50 = 10000x50\n",
    "\n",
    "#     # Weights Update\n",
    "#     if regularization == 'L1':\n",
    "#         model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta)) + reg_lambda * np.sign(model['W2']) # 50x10000 * 10000x9 = 50x9 # -1 if x < 0, 0 if x==0, 1 if x > 0\n",
    "#         model['W1'] -= lr * (images.T.dot(hidden_layer_delta)) + reg_lambda * np.sign(model['W1']) # 784x10000 * 10000x50 = 784x50\n",
    "#     elif regularization == 'L2':\n",
    "#         model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta)) + reg_lambda * model['W2'] # 50x10000 * 10000x9 = 50x9  \n",
    "#         model['W1'] -= lr * (images.T.dot(hidden_layer_delta)) + reg_lambda * model['W1'] # 784x10000 * 10000x50 = 784x50\n",
    "#     else:\n",
    "#         model['W2'] -= lr * (hidden_layer.T.dot(output_layer_delta))\n",
    "#         model['W1'] -= lr * (images.T.dot(hidden_layer_delta))\n",
    "        \n",
    "    \n",
    "#     model['b2'] -= lr * np.mean(output_layer_delta) # \n",
    "#     model['b1'] -= lr * np.mean(hidden_layer_delta) #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
